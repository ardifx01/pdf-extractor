{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8b751a",
   "metadata": {},
   "source": [
    "## Alur Konversi PDF ke Markdown/JSON\n",
    "#### 1. Inisialisasi & Setup\n",
    "- **Import library dan setup direktori**  \n",
    "    Langsung di script/notebook, bukan fungsi khusus.\n",
    "\n",
    "#### 2. Loop untuk Setiap File PDF\n",
    "- **Fungsi utama:** `process_pdf(pdf_file, ...)`\n",
    "- **Inisialisasi model YOLO:**  \n",
    "    `model = YOLO(get_latest_yolo_model_path())`\n",
    "\n",
    "#### 3. Cek Apakah File Sudah Pernah Diproses\n",
    "- **Fungsi:** `check_json_file_exists(json_result_path)`\n",
    "\n",
    "#### 4. Buka PDF dan Siapkan Temp Folder Gambar\n",
    "- **Library dan fungsi:** `pymupdf.open(pdf_path)`  \n",
    "    Langsung di dalam: `process_pdf`\n",
    "\n",
    "#### 5. Loop untuk Setiap Halaman PDF\n",
    "- **Di dalam:** `process_pdf`  \n",
    "    Untuk setiap halaman:\n",
    "\n",
    "##### a. Render Halaman ke Gambar\n",
    "- **Langsung di dalam:** `process_pdf`  \n",
    "    (`page.get_pixmap()`, `page_image.save()`)\n",
    "\n",
    "##### b. Deteksi Objek dengan YOLO (Opsional)\n",
    "- **Fungsi:**  \n",
    "    - `model.predict(image_path, ...)`\n",
    "    - `yolo_to_pdf_rectangles(boxes, zoom)`\n",
    "    - `draw_bounding_boxes(page, rectangles)`\n",
    "\n",
    "##### c. Simpan Halaman ke PDF Sementara\n",
    "- **Fungsi:**  \n",
    "    `pymupdf.open()`, `temp_pdf.insert_pdf()`, `temp_pdf.save()`\n",
    "\n",
    "##### d. Ekstrak Teks dengan Docling\n",
    "- **Fungsi:** `extract_text_from_pdf_page(page_pdf_path, ...)`\n",
    "\n",
    "##### e. Update JSON Hasil Sementara\n",
    "- **Langsung di dalam:** `process_pdf`  \n",
    "    (`with open(json_result_path, ...) as json_file: ...`)\n",
    "\n",
    "##### f. Logging Proses\n",
    "- **Fungsi:** `logging_process(status, message)`\n",
    "\n",
    "#### 6. Simpan JSON Hasil Akhir\n",
    "- **Langsung di dalam:** `process_pdf`  \n",
    "    (`with open(json_result_path, ...) as json_file: ...`)\n",
    "\n",
    "#### 7. Cleanup\n",
    "- **Library:**  \n",
    "    - `shutil.rmtree(temp_image_dir, ignore_errors=True)`\n",
    "    - `for f in result_dir.glob(\"*.pdf\"): f.unlink()`\n",
    "\n",
    "#### 8. Kembalikan Status Proses\n",
    "- **Fungsi:** `yield logging_process(...)` di dalam `process_pdf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b377e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "import pymupdf\n",
    "from pymupdf import Page\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6145e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions,\n",
    "    PdfPipelineOptions,\n",
    "    EasyOcrOptions,\n",
    ")\n",
    "\n",
    "from docling.datamodel.settings import settings # untuk debugging waktu konversi\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.utils.model_downloader import download_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3da662",
   "metadata": {},
   "source": [
    "## Setup direktori berdasarkan struktur folder `app/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec8e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"app/results\")\n",
    "PDF_PATH = Path(\"app/temp/pdf\")\n",
    "TEMP_IMAGE_DIR = Path(\"app/temp/image\")\n",
    "ARTIFACT_PATH = Path(\"app/models\")\n",
    "\n",
    "dir_list = [\n",
    "    OUTPUT_DIR,\n",
    "    PDF_PATH,\n",
    "    TEMP_IMAGE_DIR,\n",
    "    ARTIFACT_PATH,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a6828",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58f2e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory app\\models already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "for dir_path in dir_list:\n",
    "    exist = dir_path.exists()\n",
    "    if not exist:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Directory {dir_path} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63985ffc",
   "metadata": {},
   "source": [
    "## Mencari model YOLO dan menggunakan yang terbaru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589f8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_yolo_model_path(yolo_dir=\"app/yolo\"):\n",
    "    \"\"\"\n",
    "    Get the latest YOLO model file from the specified directory.\n",
    "    Args:\n",
    "        yolo_dir (str): Directory where YOLO model files are stored.\n",
    "    Returns:\n",
    "        Path: Path to the latest YOLO model file.\n",
    "    Raises:\n",
    "        FileNotFoundError: If no YOLO model files are found in the specified directory.\n",
    "    \"\"\"\n",
    "    yolo_files = sorted(\n",
    "        glob(str(Path(yolo_dir) / \"*.pt\")),\n",
    "        key=lambda f: os.path.getmtime(f),\n",
    "        reverse=True,\n",
    "    )\n",
    "    if not yolo_files:\n",
    "        raise FileNotFoundError(f\"YOLO model file not found at {yolo_dir}/\")\n",
    "    return Path(yolo_files[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83611e3f",
   "metadata": {},
   "source": [
    "## Mengubah bounding box pada hasil deteksi YOLO ke dalam format yang sesuai dengan PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73095ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_pdf_rectangles(boxes, zoom):\n",
    "    \"\"\"\n",
    "    Converts YOLO-format bounding boxes to PyMuPDF rectangle objects, scaling coordinates by the given zoom factor.\n",
    "\n",
    "    Args:\n",
    "        boxes (list of list or tuple): A list of bounding boxes, where each box is represented as [x0, y0, x1, y1].\n",
    "        zoom (float): The zoom factor to scale down the bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "        List of PyMuPDF Rect objects\n",
    "    \"\"\"\n",
    "    return [\n",
    "        pymupdf.Rect(\n",
    "            box[0] // zoom,  # x0\n",
    "            box[1] // zoom,  # y0\n",
    "            box[2] // zoom,  # x1\n",
    "            box[3] // zoom,  # y1\n",
    "        )\n",
    "        for box in boxes\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d41ce",
   "metadata": {},
   "source": [
    "## Menghapus komponen atau elemen yang tidak diperlukan dengan membuat box berwarna putih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2195a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(page: Page, rectangles: list[pymupdf.Rect]):\n",
    "    \"\"\"\n",
    "    Draws white bounding boxes on the given PDF page by adding redaction annotations to the specified rectangles and applying the redactions.\n",
    "\n",
    "    Args:\n",
    "        page (Page): The PDF page object to draw bounding boxes on.\n",
    "        rectangles (list[pymupdf.Rect]): A list of rectangle objects specifying the areas to be covered with bounding boxes.\n",
    "\n",
    "    Returns:\n",
    "        Page: The modified PDF page with the bounding boxes applied.\n",
    "    \"\"\"\n",
    "    for rect in rectangles:\n",
    "        page.add_redact_annot(rect, fill=(1, 1, 1)) # Fill with white color\n",
    "    page.apply_redactions() # Apply the redactions to the page\n",
    "    return page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903ddff",
   "metadata": {},
   "source": [
    "## Proses konversi PDF ke dalam markdown menggunakan Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe19bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_page(\n",
    "    src_path, result_path, create_markdown, number_thread, force_full_page_ocr=False\n",
    "):\n",
    "    \"\"\"Extract text from a PDF page using OCR if necessary.\n",
    "\n",
    "    Args:\n",
    "        - src_path (str): Path to the source PDF file.\n",
    "        - result_path (str): Path to save the result.\n",
    "        - create_markdown (bool): Whether to create a markdown file.\n",
    "        - number_thread (int): Number of threads to use for OCR.\n",
    "        - force_full_page_ocr (bool): Whether to force full page OCR. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        - text (str): Extracted text from the PDF page.\n",
    "        - doc_conversion_secs (float): Time taken for document conversion.\n",
    "    \"\"\"\n",
    "\n",
    "    accelerator_options = AcceleratorOptions(\n",
    "        num_threads=number_thread, device=AcceleratorDevice.AUTO\n",
    "    ) # Jumlah thread yang digunakan selama proses, defaultnya 4.\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.artifacts_path = ARTIFACT_PATH\n",
    "    pipeline_options.accelerator_options = accelerator_options\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.do_table_structure = True\n",
    "    pipeline_options.images_scale = 2.0\n",
    "    pipeline_options.table_structure_options.do_cell_matching = True\n",
    "    pipeline_options.generate_picture_images = True\n",
    "    settings.debug.profile_pipeline_timings = True\n",
    "\n",
    "    # Referensi: \n",
    "    # - https://docling-project.github.io/docling/examples/custom_convert/\n",
    "    # - https://docling-project.github.io/docling/examples/run_with_accelerator/\n",
    "\n",
    "    # pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
    "    #     lang=[\"eng\", \"id\"],\n",
    "    #     force_full_page_ocr=force_full_page_ocr,\n",
    "    #     tesseract_cmd=\"tesseract\",\n",
    "    # )\n",
    "\n",
    "\n",
    "    pipeline_options.ocr_options = EasyOcrOptions(\n",
    "        lang=[\"en\", \"id\"],\n",
    "        force_full_page_ocr=force_full_page_ocr,\n",
    "    )\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        allowed_formats=[InputFormat.PDF, InputFormat.IMAGE],\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(\n",
    "                pipeline_options=pipeline_options\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    conv_result = converter.convert(src_path)\n",
    "    doc_conversion_secs = round(conv_result.timings[\"pipeline_total\"].times[0], 2)\n",
    "    text = conv_result.document.export_to_markdown(escape_underscores=False)\n",
    "\n",
    "    confidence_data = conv_result.confidence.model_dump()\n",
    "\n",
    "    # Cek jika teks kosong\n",
    "    if len(text.strip()) == 0 and force_full_page_ocr is False:\n",
    "        # If the text is empty, it might be a scanned PDF, so we run OCR again with force_full_page_ocr=True\n",
    "        return None, doc_conversion_secs, confidence_data\n",
    "\n",
    "    if create_markdown:\n",
    "        md_filename = f\"{result_path}.md\"\n",
    "        with open(md_filename, \"w+\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(text)\n",
    "\n",
    "    return text, doc_conversion_secs, confidence_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637dec3",
   "metadata": {},
   "source": [
    "## Fungsi bantuan untuk logging proses ke halaman Streamlit dan pengecekan file json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4302f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_process(status: str, message: str):\n",
    "    \"\"\"Logs the process status and message.\n",
    "\n",
    "    Args:\n",
    "        status (str): The status of the process.\n",
    "        message (str): The message to log.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": status,\n",
    "        \"message\": message,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b0ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_json_file_exists(file_path: Any | Path):\n",
    "    \"\"\"Checks if a JSON file exists and is have content.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file exists and has content, False otherwise.\n",
    "    \"\"\"\n",
    "    if file_path.exists():\n",
    "        json_content = json.loads(file_path.read_text(encoding=\"utf-8\"))\n",
    "        total_pages = json_content.get(\"total_page\", 0) or 0\n",
    "        total_page_extracted = len(json_content.get(\"content\", [])) or 0\n",
    "        if total_pages == total_page_extracted:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e419a",
   "metadata": {},
   "source": [
    "## Pemrosesan Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36caf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(\n",
    "    pdf_file: str,\n",
    "    idx: int = 1,\n",
    "    create_markdown=False,\n",
    "    overwrite=True,\n",
    "    exclude_object=True,\n",
    "    number_thread: int = 4,\n",
    "    output_dir: str | Path = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a PDF file, extracting text and optionally creating markdown files.\n",
    "    Args:\n",
    "        pdf_file (str): Path to the PDF file to process.\n",
    "        idx (int): Index of the PDF file in the processing queue.\n",
    "        create_markdown (bool): Whether to create markdown files from the extracted text.\n",
    "        overwrite (bool): Whether to overwrite existing JSON results.\n",
    "        exclude_object (bool): Whether to exclude objects detected by YOLO.\n",
    "        number_thread (int): Number of threads to use for OCR.\n",
    "        output_dir (str | Path): Directory to save the output results.\n",
    "    Yields:\n",
    "        dict: Status messages indicating the progress of the processing.\n",
    "    \"\"\"\n",
    "    MODEL_YOLO = get_latest_yolo_model_path()\n",
    "    print(f\"Using YOLO model: {MODEL_YOLO}\")\n",
    "    model = YOLO(MODEL_YOLO)\n",
    "    base_name = Path(pdf_file).stem\n",
    "    pdf_path = pdf_file\n",
    "    total = 0 # Initialize total pages in the PDF file\n",
    "\n",
    "    list_models = [f for f in ARTIFACT_PATH.rglob(\"*\") if f.is_file()]\n",
    "    if not list_models:\n",
    "        # Check if the models are already downloaded\n",
    "        # If not, download them\n",
    "        print(\"Models not found, downloading...\")\n",
    "        download_models(\n",
    "            output_dir=ARTIFACT_PATH, progress=True\n",
    "        )  # Ensure models are downloaded\n",
    "\n",
    "    if create_markdown:\n",
    "        result_dir = output_dir / base_name\n",
    "        result_dir.mkdir(exist_ok=True)\n",
    "        json_result_path = result_dir / f\"{base_name}.json\"\n",
    "    else:\n",
    "        result_dir = output_dir\n",
    "        json_result_path = result_dir / f\"{base_name}.json\"\n",
    "\n",
    "    if not overwrite and check_json_file_exists(json_result_path):\n",
    "        yield logging_process(\n",
    "            \"info\", f\"[SKIP] JSON result already exists for {base_name}, skipping.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with pymupdf.open(pdf_path) as pdf:\n",
    "            result_json = {\"content\": [], \"total_page\": pdf.page_count}\n",
    "            temp_image_dir = TEMP_IMAGE_DIR / base_name\n",
    "            temp_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "            total = pdf.page_count\n",
    "            total_times = 0\n",
    "\n",
    "            for i, page in enumerate(pdf.pages()):\n",
    "                page_index = i + 1\n",
    "                zoom = 3\n",
    "                mat = pymupdf.Matrix(zoom, zoom)\n",
    "                page_image = page.get_pixmap(matrix=mat)\n",
    "                image_path = temp_image_dir / f\"{base_name}-page-{page_index}.png\"\n",
    "                page_image.save(str(image_path))\n",
    "\n",
    "                if exclude_object:\n",
    "                    # YOLO inference\n",
    "                    results = model.predict(str(image_path), verbose=False, conf=0.5)\n",
    "\n",
    "                    result_dict = {\n",
    "                        \"cls\": results[0].boxes.cls.cpu().numpy(),\n",
    "                        \"box\": results[0].boxes.xyxy.cpu().numpy(),\n",
    "                    }\n",
    "\n",
    "                    # Filter boxes based on class values\n",
    "                    boxes = []\n",
    "                    for i, cls_value in enumerate(result_dict[\"cls\"]):\n",
    "                        if cls_value == 0:\n",
    "                            boxes.append(result_dict[\"box\"][i])\n",
    "\n",
    "                    rectangles = yolo_to_pdf_rectangles(boxes, zoom) if boxes else []\n",
    "                    if rectangles:\n",
    "                        page = draw_bounding_boxes(page, rectangles)\n",
    "\n",
    "                    del results, result_dict, boxes, rectangles\n",
    "                    gc.collect()\n",
    "\n",
    "                page_pdf_path = result_dir / f\"{base_name}-page-{page_index}.pdf\"\n",
    "                with pymupdf.open() as temp_pdf:\n",
    "                    temp_pdf.insert_pdf(\n",
    "                        pdf,\n",
    "                        from_page=page.number,\n",
    "                        to_page=page.number,\n",
    "                        links=False,\n",
    "                        widgets=False,\n",
    "                    )\n",
    "                    temp_pdf.save(str(page_pdf_path), garbage=4, deflate=True)\n",
    "\n",
    "                # Checking if the PDF is scanned and needs OCR\n",
    "                markdown_text, time_spent, confidence_data = extract_text_from_pdf_page(\n",
    "                    page_pdf_path,\n",
    "                    result_dir / f\"{base_name}-page-{page_index}\",\n",
    "                    create_markdown,\n",
    "                    number_thread,\n",
    "                    force_full_page_ocr=False,\n",
    "                )\n",
    "                with pymupdf.open() as temp_pdf:\n",
    "                    temp_pdf.insert_pdf(\n",
    "                        pdf,\n",
    "                        from_page=page.number,\n",
    "                        to_page=page.number,\n",
    "                        links=False,\n",
    "                        widgets=False,\n",
    "                    )\n",
    "                    temp_pdf.save(str(page_pdf_path), garbage=4, deflate=True)\n",
    "\n",
    "                if markdown_text is None:\n",
    "                    yield logging_process(\n",
    "                        \"info\",\n",
    "                        f\"Page {page_index}/{pdf.page_count} of {base_name} is empty, running OCR again.\",\n",
    "                    )\n",
    "                    # If the text is empty, it might be a scanned PDF, so we run OCR again with force_full_page_ocr=True\n",
    "                    markdown_text, time_spent, confidence_data = (\n",
    "                        extract_text_from_pdf_page(\n",
    "                            page_pdf_path,\n",
    "                            result_dir / f\"{base_name}-page-{page_index}\",\n",
    "                            create_markdown,\n",
    "                            number_thread,\n",
    "                            force_full_page_ocr=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                temp_content = {\n",
    "                    \"page\": page_index,\n",
    "                    \"content\": markdown_text,\n",
    "                    \"duration\": time_spent,\n",
    "                }\n",
    "\n",
    "                confidence_data[\"pages\"][0] = {\n",
    "                    k: (None if isinstance(v, float) and math.isnan(v) else v)\n",
    "                    for k, v in confidence_data[\"pages\"][0].items()\n",
    "                }\n",
    "\n",
    "                temp_content.update(confidence_data[\"pages\"][0])\n",
    "\n",
    "                result_json[\"content\"].append(temp_content)\n",
    "\n",
    "                total_times += time_spent\n",
    "\n",
    "                yield logging_process(\n",
    "                    \"info\",\n",
    "                    f\"Processed page {page_index}/{pdf.page_count} of {base_name} in {time.strftime('%H:%M:%S', time.gmtime(time_spent))}\",\n",
    "                )\n",
    "\n",
    "                del (\n",
    "                    mat,\n",
    "                    page_image,\n",
    "                    page_pdf_path,\n",
    "                    markdown_text,\n",
    "                    time_spent,\n",
    "                )\n",
    "                gc.collect()\n",
    "\n",
    "                with open(json_result_path, \"w+\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(result_json, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "            # Save the total time taken for processing the PDF\n",
    "            result_json[\"total_time\"] = round(total_times, 2)\n",
    "\n",
    "            with open(json_result_path, \"w+\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(\n",
    "                    result_json,\n",
    "                    json_file,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=2,\n",
    "                    allow_nan=False,\n",
    "                )\n",
    "\n",
    "        # Remove temp PDF files\n",
    "        for f in result_dir.glob(\"*.pdf\"):\n",
    "            f.unlink()\n",
    "        shutil.rmtree(temp_image_dir, ignore_errors=True)\n",
    "\n",
    "        yield logging_process(\"success\", f\"Finished processing PDF: {base_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        yield logging_process(\"error\", f\"Failed to process PDF {idx + 1}/{total}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4187ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using YOLO model: app\\yolo\\best-1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\Magang\\pdf-extractor\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'info', 'message': 'Processed page 1/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:08'}\n",
      "{'status': 'info', 'message': 'Processed page 2/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:10'}\n",
      "{'status': 'info', 'message': 'Processed page 3/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:14'}\n",
      "{'status': 'info', 'message': 'Processed page 4/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:17'}\n",
      "{'status': 'info', 'message': 'Processed page 5/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:09'}\n",
      "{'status': 'info', 'message': 'Processed page 6/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:10'}\n",
      "{'status': 'info', 'message': 'Processed page 7/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:15'}\n",
      "{'status': 'info', 'message': 'Processed page 8/8 of kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp in 00:00:03'}\n",
      "{'status': 'success', 'message': 'Finished processing PDF: kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp'}\n"
     ]
    }
   ],
   "source": [
    "for status in process_pdf(\n",
    "    \"app/temp/pdf/kap_pjj_penilaian_aset_tak_berwujud_djp_bagi_pegawai_djp.pdf\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "):\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f3d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
